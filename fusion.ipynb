{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from core.vz_resnet import VZArchitectureParameters\n",
    "from core.vz_resnet import VZResnet\n",
    "\n",
    "model_architecture = VZArchitectureParameters(\n",
    "        input_size=torch.Size((1, 4, 4)),\n",
    "        policy_size=4,\n",
    "        res_channels=8,\n",
    "        res_blocks=2, \n",
    "        value_head_res_channels=8,\n",
    "        value_head_res_blocks=2,\n",
    "        policy_head_res_channels=8,\n",
    "        policy_head_res_blocks=2,\n",
    "        kernel_size=3,\n",
    "        policy_fc_size=32,\n",
    "        value_fc_size=32\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.vz_resnet import ConvBlock\n",
    "\n",
    "\n",
    "c = ConvBlock(4, 8, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import GLOB_FLOAT_TYPE\n",
    "from envs._2048.vectenv import _2048Env\n",
    "import torch\n",
    "\n",
    "num_boards = 4096\n",
    "env = _2048Env(num_boards, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VZResnet(\n",
       "  (input_block): ConvBlock(\n",
       "    (conv): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (res_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (policy_head): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=4, bias=True)\n",
       "  )\n",
       "  (value_head): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VZResnet(model_architecture)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.9 ms ± 901 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r1 = model(env.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "did not find fuser method for: (<class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfuse()\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/vz_resnet.py:105\u001b[0m, in \u001b[0;36mVZResnet.fuse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_block\u001b[39m.\u001b[39;49mfuse()\n\u001b[1;32m    106\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_blocks:\n\u001b[1;32m    107\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(b, ResidualBlock):\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/vz_resnet.py:38\u001b[0m, in \u001b[0;36mConvBlock.fuse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     torch\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mfuse_modules(\u001b[39mself\u001b[39;49m, [\u001b[39m'\u001b[39;49m\u001b[39mconv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbn\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m], inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python3/lib/python3.8/site-packages/torch/ao/quantization/fuse_modules.py:158\u001b[0m, in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse_modules\u001b[39m(model, modules_to_fuse, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fuser_func\u001b[39m=\u001b[39mfuse_known_modules, fuse_custom_config_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Fuses a list of modules into a single module\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    Fuses only the following sequence of modules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m _fuse_modules(\n\u001b[1;32m    159\u001b[0m         model,\n\u001b[1;32m    160\u001b[0m         modules_to_fuse,\n\u001b[1;32m    161\u001b[0m         is_qat\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    162\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    163\u001b[0m         fuser_func\u001b[39m=\u001b[39;49mfuser_func,\n\u001b[1;32m    164\u001b[0m         fuse_custom_config_dict\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python3/lib/python3.8/site-packages/torch/ao/quantization/fuse_modules.py:96\u001b[0m, in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     92\u001b[0m     model \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(model)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(module_element, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m module_element \u001b[39min\u001b[39;00m modules_to_fuse):\n\u001b[1;32m     95\u001b[0m     \u001b[39m# Handle case of modules_to_fuse being a list\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     _fuse_modules_helper(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# Handle case of modules_to_fuse being a list of lists\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mfor\u001b[39;00m module_list \u001b[39min\u001b[39;00m modules_to_fuse:\n",
      "File \u001b[0;32m~/miniconda3/envs/python3/lib/python3.8/site-packages/torch/ao/quantization/fuse_modules.py:84\u001b[0m, in \u001b[0;36m_fuse_modules_helper\u001b[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     81\u001b[0m     mod_list\u001b[39m.\u001b[39mappend(_get_module(model, item))\n\u001b[1;32m     83\u001b[0m \u001b[39m# Fuse list of modules\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m new_mod_list \u001b[39m=\u001b[39m fuser_func(mod_list, is_qat, additional_fuser_method_mapping)\n\u001b[1;32m     86\u001b[0m \u001b[39m# Replace original module list with fused module list\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mfor\u001b[39;00m i, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(modules_to_fuse):\n",
      "File \u001b[0;32m~/miniconda3/envs/python3/lib/python3.8/site-packages/torch/ao/quantization/fuse_modules.py:52\u001b[0m, in \u001b[0;36mfuse_known_modules\u001b[0;34m(mod_list, is_qat, additional_fuser_method_mapping)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns a list of modules that fuses the operations specified\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m in the input module list.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mthe fused operation. The rest of the elements are set to nn.Identity()\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m types \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(type_before_parametrizations(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m mod_list)\n\u001b[0;32m---> 52\u001b[0m fuser_method \u001b[39m=\u001b[39m get_fuser_method(types, additional_fuser_method_mapping)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m fuser_method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot fuse modules: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(types))\n",
      "File \u001b[0;32m~/miniconda3/envs/python3/lib/python3.8/site-packages/torch/ao/quantization/fuser_method_mappings.py:190\u001b[0m, in \u001b[0;36mget_fuser_method\u001b[0;34m(op_list, additional_fuser_method_mapping)\u001b[0m\n\u001b[1;32m    187\u001b[0m all_mappings \u001b[39m=\u001b[39m get_combined_dict(_DEFAULT_OP_LIST_TO_FUSER_METHOD,\n\u001b[1;32m    188\u001b[0m                                  additional_fuser_method_mapping)\n\u001b[1;32m    189\u001b[0m fuser_method \u001b[39m=\u001b[39m all_mappings\u001b[39m.\u001b[39mget(op_list, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[39massert\u001b[39;00m fuser_method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mdid not find fuser method for: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(op_list)\n\u001b[1;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m fuser_method\n",
      "\u001b[0;31mAssertionError\u001b[0m: did not find fuser method for: (<class 'torch.ao.nn.intrinsic.modules.fused.ConvReLU2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>) "
     ]
    }
   ],
   "source": [
    "model.fuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.8 ms ± 3.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit r2 = model(env.states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
