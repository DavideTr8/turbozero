{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marshingjay/miniconda3/envs/python3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from env2048.vectenv import Vectorized2048Env\n",
    "from env2048.vectmcts import Vectorized2048MCTSLazy\n",
    "from az_resnet import AZResnet, AZResnetArchitectureParameters\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_boards = 100\n",
    "v = Vectorized2048Env(num_boards, device)\n",
    "model = AZResnet(AZResnetArchitectureParameters(\n",
    "    input_size=torch.Size((1, 4, 4)),\n",
    "    policy_size=4,\n",
    "    res_channels=8,\n",
    "    res_blocks=2,\n",
    "    value_head_res_channels=8,\n",
    "    value_head_res_blocks=2,\n",
    "    policy_head_res_channels=8,\n",
    "    policy_head_res_blocks=2,\n",
    "    kernel_size=3,\n",
    "    policy_fc_size=32,\n",
    "    value_fc_size=32\n",
    "))\n",
    "mc = Vectorized2048MCTSLazy(v, model, 1)\n",
    "v.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_steps(steps, iters, depth):\n",
    "    for _ in range(steps):\n",
    "        moves = mc.choose_action(iters, depth)\n",
    "        v.step(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         99819 function calls (89029 primitive calls) in 8.249 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1950    5.371    0.003    5.371    0.003 {built-in method torch.batch_norm}\n",
      "      155    0.810    0.005    1.066    0.007 vectenv.py:75(get_progressions)\n",
      "     2330    0.769    0.000    0.769    0.000 {built-in method torch.conv2d}\n",
      "      520    0.389    0.001    0.389    0.001 {built-in method torch._C._nn.linear}\n",
      "     1115    0.262    0.000    0.262    0.000 {built-in method torch.any}\n",
      "     1950    0.055    0.000    0.055    0.000 {built-in method torch.relu}\n",
      "      155    0.052    0.000    0.082    0.001 vectenv.py:103(merge)\n",
      "      310    0.045    0.000    0.060    0.000 vectenv.py:94(rotate_by_amnts)\n",
      "    18980    0.043    0.000    0.043    0.000 module.py:1194(__getattr__)\n",
      " 9360/130    0.042    0.000    6.787    0.052 module.py:1124(_call_impl)\n",
      "     1950    0.039    0.000    5.488    0.003 batchnorm.py:134(forward)\n",
      " 2080/520    0.034    0.000    6.777    0.013 container.py:137(forward)\n",
      "      160    0.034    0.000    0.151    0.001 vectenv.py:49(get_legal_moves)\n",
      "      780    0.031    0.000    4.812    0.006 az_resnet.py:36(forward)\n",
      "      155    0.025    0.000    1.421    0.009 vectenv.py:33(step)\n",
      "     1950    0.019    0.000    0.019    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "     1950    0.018    0.000    5.405    0.003 functional.py:2407(batch_norm)\n",
      "       25    0.016    0.001    7.788    0.312 vectmcts.py:27(iterate)\n",
      "     1240    0.013    0.000    0.013    0.000 {method 'flip' of 'torch._C._TensorBase' objects}\n",
      "      155    0.013    0.000    1.093    0.007 vectenv.py:85(spawn_tiles)\n",
      "      310    0.012    0.000    0.012    0.000 {built-in method torch.sort}\n",
      "     1690    0.010    0.000    0.700    0.000 conv.py:456(forward)\n",
      "     2015    0.010    0.000    0.010    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "     9360    0.009    0.000    0.009    0.000 {built-in method torch._C._get_tracing_state}\n",
      "     1950    0.009    0.000    0.009    0.000 functional.py:2390(_verify_batch_size)\n",
      "      620    0.006    0.000    0.006    0.000 {built-in method torch.rsub}\n",
      "      280    0.006    0.000    0.006    0.000 {built-in method torch.multinomial}\n",
      "     1950    0.006    0.000    0.066    0.000 activation.py:97(forward)\n",
      "     1690    0.006    0.000    0.680    0.000 conv.py:448(_conv_forward)\n",
      "        5    0.005    0.001    8.227    1.645 vectmcts.py:37(choose_action)\n",
      "      155    0.004    0.000    0.148    0.001 vectenv.py:118(push_moves)\n",
      "      130    0.004    0.000    6.785    0.052 az_resnet.py:85(forward)\n",
      "      260    0.004    0.000    0.004    0.000 {method 'flatten' of 'torch._C._TensorBase' objects}\n",
      "     1950    0.004    0.000    0.060    0.000 functional.py:1446(relu)\n",
      "      785    0.004    0.000    0.004    0.000 {built-in method torch.logical_and}\n",
      "      130    0.004    0.000    0.004    0.000 {method 'softmax' of 'torch._C._TensorBase' objects}\n",
      "      155    0.004    0.000    0.154    0.001 vectenv.py:46(update_invalid_mask)\n",
      "      775    0.004    0.000    0.004    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "      155    0.004    0.000    0.004    0.000 {method 'amax' of 'torch._C._TensorBase' objects}\n",
      "      310    0.003    0.000    0.003    0.000 {built-in method torch.gather}\n",
      "      435    0.003    0.000    0.003    0.000 {built-in method torch.logical_not}\n",
      "     1950    0.003    0.000    0.003    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "     2080    0.003    0.000    0.005    0.000 container.py:129(__iter__)\n",
      "      160    0.003    0.000    0.003    0.000 {built-in method torch.concat}\n",
      "      520    0.003    0.000    0.393    0.001 linear.py:113(forward)\n",
      "      180    0.003    0.000    0.003    0.000 {built-in method torch.where}\n",
      "      640    0.003    0.000    0.003    0.000 {built-in method torch.logical_or}\n",
      "      155    0.002    0.000    0.002    0.000 {built-in method torch.arange}\n",
      "       25    0.002    0.000    0.004    0.000 vectmcts.py:17(choose_action_with_puct)\n",
      "      155    0.002    0.000    0.002    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "      620    0.002    0.000    0.002    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
      "     1690    0.002    0.000    0.003    0.000 batchnorm.py:405(_check_input_dim)\n",
      "     1950    0.002    0.000    0.003    0.000 __init__.py:31(__get__)\n",
      "      155    0.002    0.000    0.002    0.000 {method 'masked_fill_' of 'torch._C._TensorBase' objects}\n",
      "      275    0.002    0.000    0.002    0.000 {method 'squeeze' of 'torch._C._TensorBase' objects}\n",
      "        1    0.002    0.002    8.249    8.249 2763437642.py:1(run_for_steps)\n",
      "      620    0.001    0.000    0.009    0.000 _tensor.py:26(wrapped)\n",
      "     2080    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "     1950    0.001    0.000    0.001    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "      155    0.001    0.000    0.001    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
      "      620    0.001    0.000    0.007    0.000 _tensor.py:637(__rsub__)\n",
      "     2080    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "     1950    0.001    0.000    0.001    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "      260    0.001    0.000    0.005    0.000 flatten.py:44(forward)\n",
      "     1950    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "     2080    0.001    0.000    0.001    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "       50    0.001    0.000    0.001    0.000 {built-in method torch.sum}\n",
      "     1950    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method torch.argmax}\n",
      "      130    0.000    0.000    0.004    0.000 functional.py:1804(softmax)\n",
      "      260    0.000    0.000    0.000    0.000 batchnorm.py:296(_check_input_dim)\n",
      "       30    0.000    0.000    0.000    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
      "      620    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method torch.sqrt}\n",
      "        1    0.000    0.000    8.249    8.249 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    8.249    8.249 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%prun -s tottime run_for_steps(5, 5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
