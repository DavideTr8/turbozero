{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from train import MCTS_HYPERPARAMETERS, load_from_checkpoint, collect_episode, train, rotate_training_examples\n",
    "\n",
    "from model_3d import MonteCarlo3d\n",
    "from utils import input_to_tensor_3d\n",
    "import torch.multiprocessing as mp\n",
    "from train import save_checkpoint, load_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_LOAD = \"\" # place filename of checkpoint here, otherwise leave empty\n",
    "LOAD_REPLAY_MEMORY = True\n",
    "\n",
    "# HYPERPARAMETERS (will be ignored if loading from a checkpoint)\n",
    "hyperparameters = MCTS_HYPERPARAMETERS() # use kwargs to specify non-default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if MODEL_TO_LOAD:\n",
    "#     env, mcts, episode, model, optimizer, hyperparameters, metric_history, replay_memory, run_tag = load_from_checkpoint(MODEL_TO_LOAD, load_replay_memory=LOAD_REPLAY_MEMORY)\n",
    "# else:\n",
    "#     env = _2048Env()\n",
    "#     model = MonteCarlo3d()\n",
    "#     mcts = MCTS_Evaluator(model, env, input_to_tensor_3d, training=True)\n",
    "#     replay_memory = ReplayMemory(hyperparameters.replay_memory_size)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=hyperparameters.lr, weight_decay=hyperparameters.weight_decay)\n",
    "#     metric_history = MetricsHistory()\n",
    "#     run_tag = ''     \n",
    "#     episode = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model, optimizer, hyperparameters, metrics_history, replay_memory, run_tag = load_from_checkpoint('3DMCTS_ep2200.pt', MonteCarlo3d, load_replay_memory=True)\n",
    "hyperparameters.num_episodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enque_and_train(results):\n",
    "    training_examples, reward, moves, high_square= results\n",
    "    training_examples = rotate_training_examples(training_examples)\n",
    "    replay_memory.extend(training_examples)\n",
    "    \n",
    "    if replay_memory.size() >= hyperparameters.minibatch_size:\n",
    "        value_loss, prob_loss, total_loss = train(replay_memory.sample(hyperparameters.minibatch_size), model, optimizer, tensor_conversion_fn=input_to_tensor_3d)\n",
    "        new_best = metrics_history.add_history({\n",
    "                'reward': reward,\n",
    "                'game_moves': moves,\n",
    "                'prob_loss': prob_loss,\n",
    "                'value_loss': value_loss,\n",
    "                'total_loss': total_loss,\n",
    "                'high_square': high_square\n",
    "            })\n",
    "        metrics_history.plot_history(window_size=100)\n",
    "        if new_best:\n",
    "            print('*** NEW BEST REWARD ***')\n",
    "        print(f'[EPISODE {metrics_history.episodes}] Total Loss: {total_loss}, Prob Loss {prob_loss}, Value Loss {value_loss}, Reward {reward}, Moves: {moves}, Highest Square: {high_square}')\n",
    "        if metrics_history.episodes % hyperparameters.checkpoint_every == 0:\n",
    "            print('Saving model checkpoint...')\n",
    "            save_checkpoint(metrics_history.episodes, model, optimizer, hyperparameters, metrics_history, replay_memory, run_tag='3DMCTS', save_replay_memory=True)\n",
    "            print('Saved model checkpoint!')\n",
    "    else:\n",
    "        print(f'Replay memory size not large enough, {replay_memory.size()} < {hyperparameters.minibatch_size}')\n",
    "    \n",
    "    \n",
    "\n",
    "with mp.Pool(mp.cpu_count() - 1) as p:\n",
    "    results = []\n",
    "    for n in range(metrics_history.episodes, hyperparameters.num_episodes):\n",
    "        results.append(p.apply_async(collect_episode, (model, hyperparameters, input_to_tensor_3d, ), callback=enque_and_train, error_callback=print))\n",
    "    for r in results:\n",
    "        r.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train import test_network\n",
    "\n",
    "# test_network(model, hyperparameters, input_to_tensor_3d, debug_print=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "644e7a931897874d9649e2ac8857f34ca516c0cb177a94235220b02fad034c18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
