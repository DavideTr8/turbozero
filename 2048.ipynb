{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='training_2048.log', filemode='a', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logging.info('Starting training')\n",
    "\n",
    "from envs._2048.trainer import _2048Trainer\n",
    "from core.hyperparameters import LZHyperparameters\n",
    "from core.lz_resnet import LZArchitectureParameters, LZResnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marshingjay/Repos/lazyzero/envs/_2048/torchscripts.py:60: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask0 = torch.tensor([[[[-1e5, 1]]]], dtype=dtype, device=device, requires_grad=False)\n",
      "/Users/marshingjay/Repos/lazyzero/envs/_2048/torchscripts.py:61: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask1 = torch.tensor([[[[1], [-1e5]]]], dtype=dtype, device=device, requires_grad=False)\n",
      "/Users/marshingjay/Repos/lazyzero/envs/_2048/torchscripts.py:62: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask2 = torch.tensor([[[[1, -1e5]]]], dtype=dtype, device=device, requires_grad=False)\n",
      "/Users/marshingjay/Repos/lazyzero/envs/_2048/torchscripts.py:63: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask3 = torch.tensor([[[[-1e5], [1]]]], dtype=dtype, device=device, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "# --------- SETUP ---------\n",
    "from envs._2048.trainer import init_2048_trainer_from_checkpoint\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CHECKPOINT_FILE = ''\n",
    "NUM_PARALLEL_ENVS = 5 # you can go much higher on a GPU, depending on the model size / state size\n",
    "\n",
    "# performance\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "if CHECKPOINT_FILE:\n",
    "    trainer: _2048Trainer = init_2048_trainer_from_checkpoint(NUM_PARALLEL_ENVS, CHECKPOINT_FILE, device)\n",
    "else:\n",
    "    run_tag = '' # TODO: add run tag\n",
    "    \n",
    "    model_architecture = LZArchitectureParameters(\n",
    "        input_size=torch.Size((1, 4, 4)),\n",
    "        policy_size=4,\n",
    "        res_channels=16,\n",
    "        res_blocks=8, \n",
    "        value_head_res_channels=16,\n",
    "        value_head_res_blocks=4,\n",
    "        policy_head_res_channels=16,\n",
    "        policy_head_res_blocks=4,\n",
    "        kernel_size=3,\n",
    "        policy_fc_size=32,\n",
    "        value_fc_size=32\n",
    "    ) # TODO: specify model architecture parameters \n",
    "\n",
    "    hypers =LZHyperparameters(\n",
    "        # TODO: I strongly reccommend changing default hyperparamters\n",
    "        learning_rate = 1e-4,\n",
    "        num_iters_train = 5,\n",
    "        iter_depth_train = 2,\n",
    "        num_iters_eval = 5,\n",
    "        iter_depth_test = 3,\n",
    "        replay_memory_size = 10000,\n",
    "        replay_memory_min_size = 1,\n",
    "        minibatch_size = 4096,\n",
    "        minibatches_per_update = 2,\n",
    "        episodes_per_epoch=100000,\n",
    "        epsilon_decay_per_epoch=0.1,\n",
    "        eval_episodes_per_epoch=0\n",
    "    )\n",
    "\n",
    "    model = LZResnet(model_architecture).to(device)\n",
    "\n",
    "    trainer = _2048Trainer(\n",
    "        NUM_PARALLEL_ENVS,\n",
    "        model = model,\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=hypers.learning_rate),\n",
    "        hypers = hypers,\n",
    "        device = device,\n",
    "    )\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.training_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
