{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from turbozero import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marshingjay/Repos/lazyzero/envs/othello/torchscripts.py:108: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  board_size = int(states.shape[-1]) # need to wrap in int() for tracing\n"
     ]
    }
   ],
   "source": [
    "tournament = load_tournament_nb(\n",
    "    config_file='./example_configs/othello_tiny.yaml', #TODO: specify a config file\n",
    "    gpu=torch.cuda.is_available(),\n",
    "    debug=False,\n",
    "    logfile='turbozero.log',\n",
    "    verbose_logging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tournament\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/test/tournament/tournament.py:99\u001b[0m, in \u001b[0;36mTournament.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m player_ratings \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m: [])\n\u001b[1;32m     98\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather_round_robin_games(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_games)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_tournaments):\n\u001b[1;32m    100\u001b[0m     shuffle(results)\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/test/tournament/tournament.py:83\u001b[0m, in \u001b[0;36mTournament.gather_round_robin_games\u001b[0;34m(self, games_against_each_player)\u001b[0m\n\u001b[1;32m     81\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m     82\u001b[0m \u001b[39mfor\u001b[39;00m (player1, player2) \u001b[39min\u001b[39;00m combinations(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompetitors, \u001b[39m2\u001b[39m):\n\u001b[0;32m---> 83\u001b[0m     p1_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplay_games(player1\u001b[39m.\u001b[39;49mevaluator, player2\u001b[39m.\u001b[39;49mevaluator)\n\u001b[1;32m     84\u001b[0m     new_results \u001b[39m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m     \u001b[39mfor\u001b[39;00m p1_score \u001b[39min\u001b[39;00m p1_scores:\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/test/tournament/tournament.py:72\u001b[0m, in \u001b[0;36mTournament.play_games\u001b[0;34m(self, evaluator1, evaluator2)\u001b[0m\n\u001b[1;32m     70\u001b[0m     evaluator1\u001b[39m.\u001b[39mstep_evaluator(actions, terminated)\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     _, _, _, actions, terminated \u001b[39m=\u001b[39m evaluator1\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     73\u001b[0m     evaluator2\u001b[39m.\u001b[39mstep_evaluator(actions, terminated)\n\u001b[1;32m     74\u001b[0m rewards \u001b[39m=\u001b[39m evaluator1\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mget_rewards(starting_players)\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/algorithms/evaluator.py:39\u001b[0m, in \u001b[0;36mEvaluator.step\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, Optional[torch\u001b[39m.\u001b[39mTensor], torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m     38\u001b[0m     initial_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstates\u001b[39m.\u001b[39mclone()\n\u001b[0;32m---> 39\u001b[0m     probs, values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     40\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoose_actions(probs)\n\u001b[1;32m     41\u001b[0m     terminated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_env(actions)\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/algorithms/baselines/greedy.py:29\u001b[0m, in \u001b[0;36mGreedyBaseline.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m action_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\n\u001b[1;32m     23\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mparallel_envs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mpolicy_shape[\u001b[39m0\u001b[39m]),\n\u001b[1;32m     24\u001b[0m     dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     25\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m     26\u001b[0m     requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m action_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mpolicy_shape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> 29\u001b[0m     terminated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(torch\u001b[39m.\u001b[39;49mfull((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mparallel_envs, ), action_idx, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, requires_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m     30\u001b[0m     rewards \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mget_rewards(starting_players)\n\u001b[1;32m     31\u001b[0m     greedy_rewards \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mget_greedy_rewards(starting_players)\n",
      "File \u001b[0;32m~/Repos/lazyzero/core/env.py:48\u001b[0m, in \u001b[0;36mEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, actions) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpush_actions(actions)\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_turn()\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_terminated()\n",
      "File \u001b[0;32m~/Repos/lazyzero/envs/othello/env.py:69\u001b[0m, in \u001b[0;36mOthelloEnv.push_actions\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpush_actions\u001b[39m(\u001b[39mself\u001b[39m, actions):\n\u001b[1;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_to_calculate_rays:\n\u001b[0;32m---> 69\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_legal_actions() \u001b[39m# updates ray tensor\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     _, passes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_actions_traced(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mray_tensor, actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflips) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconsecutive_passes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m passes\n",
      "File \u001b[0;32m~/Repos/lazyzero/envs/othello/env.py:63\u001b[0m, in \u001b[0;36mOthelloEnv.get_legal_actions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_to_calculate_rays:\n\u001b[1;32m     62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_to_calculate_rays \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_legal_actions_traced(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstates, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mray_tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlegal_actions, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilters_and_indices) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegal_actions\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tournament.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
